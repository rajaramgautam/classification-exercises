{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1364609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "import acquire\n",
    "import prepare\n",
    "from graphviz import Graph\n",
    "\n",
    "from prepare import prep_titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbe751e",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "### In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "### For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "### Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f810a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc72fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  is_female  \\\n",
       "0         0       3  22.0      1      0   7.2500      0          0   \n",
       "1         1       1  38.0      1      0  71.2833      0          1   \n",
       "2         1       3  26.0      0      0   7.9250      1          1   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing ages\n",
    "avg_age = df.age.mean()\n",
    "df.age = df.age.fillna(avg_age)\n",
    "\n",
    "# Encode the gender column\n",
    "df[\"is_female\"] = (df.sex == \"female\").astype('int')\n",
    "\n",
    "# Encode the embarked_town\n",
    "# Embark_Town values are Southampton, Cherbourg, and Queenstown\n",
    "dummy_df = pd.get_dummies(df[['embark_town']], dummy_na=False, drop_first=True)\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"passenger_id\", \"deck\", \"class\", \"embarked\", \"sex\", \"embark_town\"])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce745ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                   0\n",
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "is_female                  0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check to make sure we don't have any nulls\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3abe4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets\n",
    "train, validate, test = prepare.split_titanic_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdcfbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out our X and y values\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada864c6",
   "metadata": {},
   "source": [
    "### Insert Exploratory Data Analysis here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e153560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most frequenly observed outcome will be our baseline\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "782abb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = (train.survived == 0).mean()\n",
    "round(baseline_accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af6806",
   "metadata": {},
   "source": [
    "### 1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2237ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = [\"age\", \"pclass\", \"fare\"]\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "# logit.fit(X_train[[\"age\", \"pclass\", \"fare\"]], y_train)\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "# Since we .fit on a subset, we .predict on that same subset of features\n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d93820",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e0d0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit1 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit1.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712e17d8",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd32d19",
   "metadata": {},
   "source": [
    "Models Created:\n",
    "\n",
    "- logit2, all Features, 0.82 accuracy\n",
    "- logit3, all features with class_weight=\"balanced\", .80 accuracy\n",
    "- logit4, only age, .62 accuracy\n",
    "- logit5, only pclass, .67 accuracy\n",
    "- logit6, C hyperparameter close to zero, .62 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0fb036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on all features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "# All features, all default hyperparameters\n",
    "logit2 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit2.predict(X_train)\n",
    "\n",
    "print(\"Model trained on all features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a395c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.8\n"
     ]
    }
   ],
   "source": [
    "# All features, but we'll use the class_weights to hold the actual ratios`\n",
    "logit3 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "\n",
    "logit3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit3.predict(X_train)\n",
    "\n",
    "accuracy = logit3.score(X_train, y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74d8ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Only Age \n",
    "features = [\"age\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f5db398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Only pclass\n",
    "features = [\"pclass\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit5 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit5.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit5.predict(X_train[features])\n",
    "accuracy = logit5.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00ebe21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features, C hyperparameter approaching 0\n",
      "Baseline is 0.62\n",
      "Accuracy of this Logistic Regression on training set: 0.64\n"
     ]
    }
   ],
   "source": [
    "# All Features, C ~ 0\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit6 = LogisticRegression(random_state=123, C=0.0001)\n",
    "\n",
    "logit6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit6.predict(X_train)\n",
    "accuracy = logit6.score(X_train, y_train)\n",
    "\n",
    "print(\"All Features, C hyperparameter approaching 0\")\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(f'Accuracy of this Logistic Regression on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb71f3c",
   "metadata": {},
   "source": [
    "### 4. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c768d77",
   "metadata": {},
   "source": [
    "Based on accuracy logit1, logit and logit3 are best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc78a8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit1 model using age, pclass, fare, and is_female as the features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       132\n",
      "           1       0.72      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's determine logit1's metrics on validate\n",
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print('Logit1 model using age, pclass, fare, and is_female as the features')\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbffde57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit2 model using all features and all model defaults\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.82       132\n",
      "           1       0.74      0.65      0.69        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit2 uses all features\n",
    "y_pred = logit2.predict(X_validate)\n",
    "\n",
    "print(\"Logit2 model using all features and all model defaults\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7c38fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       132\n",
      "           1       0.70      0.72      0.71        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.77      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit3 uses all features and class_weight='balanced'\n",
    "y_pred = logit3.predict(X_validate)\n",
    "\n",
    "print(\"Logit3 model using all features, class_weight='balanced', and all other hyperparameters as default\")\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784006e2",
   "metadata": {},
   "source": [
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d147081",
   "metadata": {},
   "source": [
    "What next?\n",
    "\n",
    "- Consider the precision and recall values from each model.\n",
    "- Experiment with more hyperparameter values and combinations\n",
    "- Handle the age nulls differently\n",
    "-- We could try filling the nulls with median age instead of average age\n",
    "-- We could drop the nulls if they weren't such a large proportion of the dataset\n",
    "- Feature engineering\n",
    "- Handling outliers\n",
    "- Scaling (we'll do this later)\n",
    "- Once we have a single model doing really well on validate, then we'll select that model to evaluate on test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c907411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit2 model using all features and all model defaults\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       110\n",
      "           1       0.78      0.71      0.74        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit2 uses all features\n",
    "y_pred = logit2.predict(X_test)\n",
    "\n",
    "print(\"Logit2 model using all features and all model defaults\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
